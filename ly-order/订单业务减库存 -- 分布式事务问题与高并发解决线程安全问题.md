<font color="green">博客地址:</font> https://blog.csdn.net/qq_41649078/article/details/91492383
 
>**减库存**可以采用同步调用（商品微服务提供接口，通过Feign调用），也可以采用异步调用（通过RabbitMq），我们**采用同步调用**，接下来我们来分析分析原因。

若采用**异步调用**的方式，我们要进行减库存，只需向RabbitMq中发送消息即可，后续我们不管，但是否减库存成功我们不得而知。若库存不足，则减库存失败，但是订单微服务中并不知道减库存失败，因此事务不会回滚，这就是<font color="red">分布式事务问题 （跨服务的事务）</font>。我们写的减库存业务从订单微服务跨越到了商品微服务，而事务是由Spring来管理的，两个tomcat两个Spring，两个事务本身没有任何关联，但是却是一个事务（减库存和创建订单应该一起完成），如果采用异步，一边微服务执行失败另一边微服务并不知道，**破坏了事务的一致性** 。

我们把异步调用变成**同步调用**，**调用如果失败就会抛出异常，事务自然回滚**（减库存操作只能放在创建订单业务的最后，因为减库存执行失败，事务自然会回滚，订单也就不会创建成功，但是如果刚开始就做减库存操作，那如果订单创建失败库存无法回滚，导致丢失库存数据），但当业务更复杂时（比如：优惠券功能、积分），有好几个服务之间调用。这时我们把那个放在最后呢？哪个放在最后都不行，这时候就要解决分布式事务问题了。
<hr>
<font color="gree">解决分布式事务问题： 

- **2PC（两阶段提交）**：第一阶段（执行阶段）：当“我”创建订单时，“我”向所有“我”要调用的微服务发一个请求，告诉他们开始执行，执行完毕后向“我”返回一条消息，告诉“我”你是执行成功了还是失败了；第二阶段：如果上一阶段所有人都执行成功，然后“我”会再发一条消息告诉所有人让其提交，如果第一阶段有一个人执行失败，则通知所有人都回滚
	- 实现复杂、还会用到一些异步通信的手段（比如：MQ），在业务执行过程中，数据锁定的范围太大（比如“我”要调用4个业务，即四个微服务，那四个微服务所对应的四张表全部锁定），在任何一个其他业务未执行完之前，所有的表都是锁定状态，因此在性能上较差，因此在电商行业里，这种互联网要求并发很高的团队里很少使用 

- 	**TCC（try-confirm-cancel）**：编写任何一个与分布式事务相关的业务功能，必须写两个业务：一个是<font size=4>确认执行业务(confirm)</font>，另一个是<font size=4>取消执行业务(cancel，即补偿业务)</font> 。比如说减库存这个业务，执行业务就是减库存，补偿业务就是加库存。基本原理：开始事务以后，让所有业务都开始执行，各完成各的，互相不等待，每个业务完成了就提交，这样就解决了两阶段提交时数据库被锁定的情况(互相要等待)，但是如果A业务提交但B业务失败了呢？所以它有一个补偿业务（大家都去提交，提交完了之后统一再把结果返回给“我”，“我”看下是全部都成功了还是有失败的，如果都成功，就confirm提交；反之，“我”会执行调用提前写好的补偿业务，也就是说它不是通过回滚的方式，而是通过补偿的方式）
	- 可以解决两阶段提交的锁定问题
	- 但是业务变得复杂了，写一个业务时必须写一个确定执行业务方法和一个补偿业务方法，除此之外还要考虑补偿方案的失败问题，当补偿方案也执行失败了呢，这时候就要考虑重试问题、人工介入问题。解决了性能问题，但是业务却变得超复杂
	- 适用于 **减库存** 业务


- **异步确保**：利用MQ实现；发送方发送完一条消息后就不管了，而接收消息那一方必须保证这个消息能处理成功，因为只要把消息发送出去不丢失，那就可以一直进行重试，直到重试成功为止
	- 事务无法回滚，不合适减库存业务
	- **关键：消息是否丢失**
	- 适用于 **转账** 业务，只要消息可靠不丢失就行


- **2PC+MQ**：异步确保结合两阶段提交

==总结==：**在电商行业中比较适合的是TCC**，虽然业务变得复杂了，但是可靠；根据业务不同使用不同的分布式事务。
<hr>
但是在我们这个小项目中，业务没有那么复杂（没有优惠券与积分等功能），在这里我们采用同步调用的方式解决。
<br>
<br>
采用<font color="gree">同步调用</font>：

-  **先查询库存，然后if判断库存，足够多时就进行减库存操作**
 	
 	 逻辑是对的，但是这么做**有线程上的安全问题**，当线程很多、高并发时，有可能引发超卖问题
- **加锁 - synchronized**
  - 安全，但是性能太差，只有一个线程可以执行，当搭了集群，同时启动好几台服务时，synchronized只锁住了当前一个tomcat，锁不了别的。
  - 看起来是安全的，但是**在分布式服务下不安全**（原因：假如商品微服务启动三台，也就是三个不同的JVM，锁的原理是内存的一种监视，三个JVM内存就不一致，则三个减库存方法的锁就不一致，只能一个JVM内部锁，不能锁住对方，因此线程不安全，放在Redis只是数据一致，不代表对象一致，锁不是一致的，JVM的范围只能作用它自己，所以不能利用synchronized锁来实现 ）
- **分布式锁**：专门来锁分布式服务的
  - **zookeeper**：
    	zookeeper是树（目录）结构，利用节点的唯一性来实现，也就意味如果有人连到zookeeper以后，会在zookeeper上创建一个树节点（在目录下创建一个节点），一旦有人创建出来，别人就不能再创建同名节点。任何一个代码进入到减库存这个地方，先去通过zookeeper在某个目录下创建一个节点，创建成功就认为得到了锁，继续执行代码；反之则失败（别人已经创建过了），返回或者wait（取决表如何设计：是否自旋），因此只有一个人可以拿到这个锁，执行完毕后删除节点释放锁，其他人可以再次创建锁 ，这样就实现单线程。---靠的是外部工具来模拟锁的机制（权限，同一时刻只能一个人操作）
  - **Redis：SETNX命令** 
    	同zookeeper原理类似，但SETNX命令只能set不存在的key，如果不存在，创建并设置value，并返回1；如果存在则会set失败，并返回0，代码运行完以后可以掉用del命令释放锁 
    - 但推荐zookeeper分布式锁，而不是Redis。原因：Redis分布式锁存在搜索问题，如果SETNX成功，成功之后开始执行代码，但是此时服务器宕机，那del命令就一直没有执行，等于这个锁一直被拿着，无法释放，以后这个值将无法再被set成功，因此我们得想办法解决死锁问题在，服务器宕机的情况下想办法剔除这个值
    - 而zookeeper可以创建临时节点，当服务器一旦断开与zookeeper连接，会自动删除该节点，自动释放锁，但逻辑实现起来较复杂。
    
  
  </br> 
但是我们<font color="green">**不推荐用锁实现，因为用了锁，就变成单线程了**</font>，相当于一执行减库存操作就先把数据库锁死，同一时刻只能有一个人来操作（类似于悲观锁，即认为线程安全问题一定会发生），在**面对高并发时，往往性能很差**。 
<hr>
  既然不推荐悲观锁，那是不是可以采用乐观锁呢？乐观锁认为线程安全问题不会发生，不加锁，但是不加锁会有线程安全问题，那如何处理这件事情呢？ 

  </br>   </br> 
 答：我们不做查询也不做判断，而是直接去进行减库存操作（上边说了，直接进行减库存会发生超卖现象，不过这要看我们sql如何写了）我们可以<font color="red">在sql内部加上条件进行判断</font>，任何人来执行，它都会有一个条件来判断库存，<font color="green">如果库存不足sql本身就会失败，事务回滚，因此不需要加锁与判断</font>，<font color="blue">本质上还是乐观锁</font>，不需要等待、阻塞，任何人都可以执行，如果执行失败会反馈失败信息，而不像是悲观锁那样线程阻塞，导致一直等待，而且还会锁数据库与表（只有执行完成才会释放)，性能上优于加锁方式，语句如下：
 </br>  </br> 

```
 "UPDATE tb_stock SET stock = stock - #{num} WHERE sku_id = #{id} AND stock >= #{num}"
```



